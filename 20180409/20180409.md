文本分析 - 詞頻
================

爬蟲
----

-   相關爬蟲細節請參考 [3/12 講義](https://github.com/ytshen1207/1062SHU/blob/master/20180312/20180312.md)
-   爬蟲日期：2018/04/02

``` r
## 載入 rvest 套件
library(rvest)

## 指定附加參數的爬蟲目標網址
url = "https://www.google.com.tw/search?q=youtuber&num=50&lr=lang_zh-TW"

## 指定文字編碼讀取頁面
search_page = read_html(url, encoding="CP950")

## 根據 CSS 選擇器規則獲取目標 nodes
search_node = html_nodes(search_page, css=".st , .r a")

## 擷取爬蟲結果的文字部分
search_result = html_text(search_node)

## 儲存爬蟲結果
#saveRDS(search_result, "20180409_files/text.rds")
```

斷詞
----

### 基本斷詞

``` r
## 載入 jiebaR 套件
library(jiebaR)
```

    ## Loading required package: jiebaRD

``` r
## 範例文本
SHU = "世新大學（Shih Hsin University，中文簡稱「世新」、英文簡稱「SHU」）位於中華民國台北市文山區的一所私立大學。

創辦人成舍我於1933年創立「北平新聞專科學校」，政府遷台後於1956年創立世界新聞職業學校，並秉持「學校為學生而辦，學生為讀書而來」的辦學原則。

1960年，改名世界新聞專科學校。

1991年，改制世界新聞傳播學院。

1997年，改名世新大學。"

## 建立一個分詞器
wk = worker()

## 進行斷詞
seg = segment(SHU, wk)
# seg = wk[SHU]
# seg = wk <= SHU

## 檢視斷詞結果
seg
```

    ##  [1] "世新"       "大學"       "Shih"       "Hsin"       "University"
    ##  [6] "中文"       "簡稱"       "世"         "新"         "英文"      
    ## [11] "簡稱"       "SHU"        "位於"       "中華民國"   "台北市"    
    ## [16] "文"         "山區"       "的"         "一所"       "私立"      
    ## [21] "大學"       "創辦人"     "成舍"       "我"         "於"        
    ## [26] "1933"       "年"         "創立"       "北平"       "新聞"      
    ## [31] "專科學校"   "政府"       "遷台"       "後"         "於"        
    ## [36] "1956"       "年"         "創立"       "世界"       "新聞"      
    ## [41] "職業"       "學校"       "並"         "秉持"       "學校"      
    ## [46] "為"         "學生"       "而辦"       "學生"       "為"        
    ## [51] "讀書"       "而來"       "的"         "辦學"       "原則"      
    ## [56] "1960"       "年"         "改名"       "世界"       "新聞"      
    ## [61] "專科學校"   "1991"       "年"         "改制"       "世界"      
    ## [66] "新聞"       "傳播學院"   "1997"       "年"         "改名"      
    ## [71] "世新"       "大學"

### 詞性標記

-   [ICTCLAS 詞性標記](https://gist.github.com/luw2007/6016931)

``` r
## 建立一個分詞器，設定 type = "tag"
wk = worker(type="tag")

## 進行斷詞
seg = segment(SHU, wk)

## 檢視斷詞結果
seg
```

    ##            n            n          eng          eng          eng 
    ##       "世新"       "大學"       "Shih"       "Hsin" "University" 
    ##           nz            v            n            a           nz 
    ##       "中文"       "簡稱"         "世"         "新"       "英文" 
    ##            v          eng            v           ns           ns 
    ##       "簡稱"        "SHU"       "位於"   "中華民國"     "台北市" 
    ##            n           ns           uj            m            b 
    ##         "文"       "山區"         "的"       "一所"       "私立" 
    ##            n            n            x            r           nr 
    ##       "大學"     "創辦人"       "成舍"         "我"         "於" 
    ##            m            m            v           ns            n 
    ##       "1933"         "年"       "創立"       "北平"       "新聞" 
    ##            l            n            x            f           nr 
    ##   "專科學校"       "政府"       "遷台"         "後"         "於" 
    ##            m            m            v            n            n 
    ##       "1956"         "年"       "創立"       "世界"       "新聞" 
    ##            n            n            c            v            n 
    ##       "職業"       "學校"         "並"       "秉持"       "學校" 
    ##           zg            n            x            n           zg 
    ##         "為"       "學生"       "而辦"       "學生"         "為" 
    ##            n            c           uj            n            n 
    ##       "讀書"       "而來"         "的"       "辦學"       "原則" 
    ##            m            m            v            n            n 
    ##       "1960"         "年"       "改名"       "世界"       "新聞" 
    ##            l            m            m            v            n 
    ##   "專科學校"       "1991"         "年"       "改制"       "世界" 
    ##            n            n            m            m            v 
    ##       "新聞"   "傳播學院"       "1997"         "年"       "改名" 
    ##            n            n 
    ##       "世新"       "大學"

### 新增停止詞

停止詞就是一些無關乎語意的詞彙，通常會在進行文本分析的時候先行清除掉。 jiebaR 本身已有內建部分常見停止詞，如果要另外新增自定義的停止詞，可以定義在一個純文字檔內，透過 worker 中的 stop\_word 參數進行引入。

``` r
## 建立一個分詞器，設定 stop_word 為自行建立的停止詞檔案路徑
wk = worker(type="tag", stop_word="20180409_files/stop_words.txt")

## 進行斷詞
seg = segment(SHU, wk)

## 檢視斷詞結果
seg
```

    ##            n            n          eng          eng          eng 
    ##       "世新"       "大學"       "Shih"       "Hsin" "University" 
    ##           nz            v            n            a           nz 
    ##       "中文"       "簡稱"         "世"         "新"       "英文" 
    ##            v          eng            v           ns           ns 
    ##       "簡稱"        "SHU"       "位於"   "中華民國"     "台北市" 
    ##            n           ns            m            b            n 
    ##         "文"       "山區"       "一所"       "私立"       "大學" 
    ##            n            x            r            m            v 
    ##     "創辦人"       "成舍"         "我"       "1933"       "創立" 
    ##           ns            n            l            n            x 
    ##       "北平"       "新聞"   "專科學校"       "政府"       "遷台" 
    ##            m            v            n            n            n 
    ##       "1956"       "創立"       "世界"       "新聞"       "職業" 
    ##            n            v            n            n            x 
    ##       "學校"       "秉持"       "學校"       "學生"       "而辦" 
    ##            n            n            c            n            n 
    ##       "學生"       "讀書"       "而來"       "辦學"       "原則" 
    ##            m            v            n            n            l 
    ##       "1960"       "改名"       "世界"       "新聞"   "專科學校" 
    ##            m            v            n            n            n 
    ##       "1991"       "改制"       "世界"       "新聞"   "傳播學院" 
    ##            m            v            n            n 
    ##       "1997"       "改名"       "世新"       "大學"

### 建立新詞彙

有時候斷詞系統無法完美的斷出預期的結果，這種情況常發生於專有名詞、姓名、簡稱等。 此時可透過新增詞彙字典的方式輔助斷詞系統進行判斷。

``` r
## 使用 new_user_word 函數建立新詞，第三個參數為詞性
new_user_word(wk, c("世新","文山區","成舍我"), c("n","n","n")) 
```

    ## [1] TRUE

``` r
## 進行斷詞
seg = segment(SHU, wk)

## 檢視斷詞結果
seg
```

    ##            n            n          eng          eng          eng 
    ##       "世新"       "大學"       "Shih"       "Hsin" "University" 
    ##           nz            v            n           nz            v 
    ##       "中文"       "簡稱"       "世新"       "英文"       "簡稱" 
    ##          eng            v           ns           ns            n 
    ##        "SHU"       "位於"   "中華民國"     "台北市"     "文山區" 
    ##            m            b            n            n            n 
    ##       "一所"       "私立"       "大學"     "創辦人"     "成舍我" 
    ##            m            v           ns            n            l 
    ##       "1933"       "創立"       "北平"       "新聞"   "專科學校" 
    ##            n            x            m            v            n 
    ##       "政府"       "遷台"       "1956"       "創立"       "世界" 
    ##            n            n            n            v            n 
    ##       "新聞"       "職業"       "學校"       "秉持"       "學校" 
    ##            n            x            n            n            c 
    ##       "學生"       "而辦"       "學生"       "讀書"       "而來" 
    ##            n            n            m            v            n 
    ##       "辦學"       "原則"       "1960"       "改名"       "世界" 
    ##            n            l            m            v            n 
    ##       "新聞"   "專科學校"       "1991"       "改制"       "世界" 
    ##            n            n            m            v            n 
    ##       "新聞"   "傳播學院"       "1997"       "改名"       "世新" 
    ##            n 
    ##       "大學"

詞頻分析
--------

### 詞頻

以先前爬取的 youtuber 相關搜尋內容進行文本分析實作。

``` r
## 載入 dplyr 套件
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
## 讀取爬蟲結果
search_result = readRDS("20180409_files/text.rds")

## 建立分詞器
wk = worker()

## 進行斷詞
seg = segment(search_result, wk)

## 將英文轉小寫
seg = tolower(seg)  # 轉大寫 toupper()

## 僅取出字元數大於 1 者計算詞彙頻率
f = freq(seg) %>%
  filter(nchar(char) > 1) %>%
  filter(char != "youtuber") %>%
  arrange(desc(freq))

## 檢視前幾筆結果
head(f)
```

    ##      char freq
    ## 1 youtube   36
    ## 2    影片   27
    ## 3    台灣   23
    ## 4    2018   18
    ## 5    訂閱   18
    ## 6    網路   16

### 文字雲

文字雲是呈現詞彙熱門程度(出現頻率)最直觀的方法。

``` r
## 安裝並載入 wordcloud 套件
# install.package("wordcloud")
library(wordcloud)
```

    ## Loading required package: RColorBrewer

``` r
## 繪製文字雲
wordcloud(f$char, f$freq, min.freq=5, colors=rainbow(1000))
```

![](20180409_files/figure-markdown_github/unnamed-chunk-7-1.png)

``` r
## 安裝並載入 wordcloud2 套件
# install.package("wordcloud2")
library(wordcloud2)

## 繪製文字雲
wordcloud2(f, minSize=5, fontFamily="微軟正黑體", color="random-light", backgroundColor="grey")
```

![](20180409_files/figure-markdown_github/unnamed-chunk-9-1.png)
